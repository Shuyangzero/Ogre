
import os,json,shutil

import numpy as np 

from ibslib.io import read,write
from ibslib.io.read import *
from ibslib.io.check import *
from ibslib.analysis import get
from ibslib.report import Report_,parse_conf
from ibslib.plot.gator import *
from ibslib.plot.utils import correct_energy
from ibslib.acsf import Driver, RSF, BaseACSF
from ibslib.libmpi import ParallelCalc,Check

from mpi4py import MPI



class GAtorReport(Report_):
    """
    Generate report for basic GAtor calculation analysis.
    
    1. Want to make another iteration of improvement on Report_ to handle 
    more generally the remake.json file. 
        - This needs to be compatible with all arguments that are passed to 
        super().__init__(**args), even if these are not in Report_ itself. 
        - Arguments then needs be to referenced and loaded into the correct
        places by the load_remake function.
    2. Arguments that are returned by the plot commands that are compatible with 
    the Report_ API should be added to the saved section calls of the Report_. 
    This makes the values more easy to reference and edit later. Adds to the 
    generality and ease of use of remake.json. 
    3. In addition, plotting may not necessarily be apart of the Report_ 
    script. Therefore, there should be load modules argument for modules
    that should be loaded in the creation of the Report_.
    4. Also, want to add an easy way to add legends above or beneath graphs. 
    It would be nice for this to just be some sort of argument or wrapper such 
    that legends are easily generated given the plotting command. Could
    incorporate into plotting API perhaps. Something like this might be 
    possible. 
    
    Mapping out the order of operations for GAtor Report:
    1. Load in settings of configuration. 
    2. Load all relevant structures, keep list of names of structures from the 
    IP and list of names for structures generated by GAtor. 
    3. Compute duplicates and remove in such a way that the structures that 
    were present first are kept and duplicates generated later are discarded. 
    Reorder the iteration at which structures were added to the pool.
    4. Output these structures to the report folder that can be easily used for
    later reference. 
    5. Calculate and plot relevant plots. Refer to the paper that I mapped out
    for the way the report will look for specifics about plots. 
    
    Arguments
    ---------

    """
    def __init__(self,
                conf_path="ui.conf", 
                exp_path="",
                acsf=True,
                dup_check=False,
                comm=None,
                report_name="report.pdf", 
                report_folder="report", 
                use_remake=False,
                report_width=12):
        
        ## Prepare MPI settings
        if comm == None:
            self.comm = MPI.COMM_WORLD
        else:
            self.comm = comm
        self.size = self.comm.Get_size()
        self.rank = self.comm.Get_rank()

        ## Safe-guard folder creation
        if self.rank == 0:
            check_dir(report_folder)
        self.comm.Barrier()

        super().__init__(
                report_name, 
                report_folder, 
                use_remake, 
                report_width)

        ## Store Report Specific Settings
        self.conf_path = conf_path
        self.exp_path = exp_path
        self.acsf = acsf
        self.dup_check = dup_check
        self.report_struct_path = os.path.join(self.report_folder, 
                                               "structures")

        ## Report specific paths
        self.ip_path = os.path.join(self.report_struct_path,
                                "ip")
        self.ga_path = os.path.join(self.report_struct_path,
                            "ga")

        ## Prepare Conf Information
        if use_remake == False:
            if self.rank == 0:
                self.conf_path = conf_path
                self.conf_dict = parse_conf(self.conf_path)

                ## Prepare Structure Information
                self.struct_dir = self.get_struct_dir()
                self.ga_dict = self.get_ga_structs()
                self.ip_dict = self.get_ip_structs()

            self.comm.Barrier()
        else:
            ## TODO: Load in remake
            pass
        

    
    def report(self, 
               figname="", 
               write_remake=True, 
               write_json=True,
               tag=True, 
               timestamp=True,
               savefig_kw={"dpi": 600}):
        """
        Creates report folder with report, the settings file, and a script to
        remake the report from the settings file. 

        """
        ### Check if remake file exists in report folder
        if self.remake:
            remake_path = os.path.join(self.report_folder, 
                                       "remake.json")
            if os.path.exists(remake_path):
                self.load_remake()

        ########################################################################
        ### Handle remake correctly here
        ########################################################################
        if self.remake == True:
            raise Exception("Remake not implemented for GAtor")

        ########################################################################
        ### Performing steps to prepare GAtor Report
        ########################################################################
        if self.rank == 0:
            self.add_header("GAtor Report",
                    text_kw =
                        {
                            "horizontalalignment": "left",
                            "verticalalignment": "center",
                            "fontweight": "bold",
                            "fontsize": 24,
                            "color": "tab:green",
                        },
                        edgecolor = "tab:green")

            ### Begin By Reporting Settings
            self.add_header("Settings",
                   text_kw =
                       {
                         "horizontalalignment": "left",
                         "verticalalignment": "center",
                         "fontweight": "bold",
                         "fontsize": 16,
                         "color": "k",
                       },
                    edgecolor = "k")
            self.add_settings()

            ### Collect Structures into Report Folder
            self.collect_structures()

            #### Starting analysis section
            self.add_header("Analysis",
                    text_kw =
                        {
                            "horizontalalignment": "left",
                            "verticalalignment": "center",
                            "fontweight": "bold",
                            "fontsize": 16,
                            "color": "k",
                        },
                        edgecolor = "k")

            ### Ready for energy plot creation
            self.add_row_energy_plots()

            ### spg and volume plots
            self.add_row_hist_plots()

        self.comm.Barrier()

        ########################################################################
        ### Performing Parallelized RSF calculation and Plotting
        ########################################################################
        if self.acsf:
            self.calc_acsf(self.ip_path)      
            self.calc_acsf(self.ga_path)
            if len(self.exp_path) > 0:
                self.calc_acsf(os.path.join(self.report_struct_path,
                                "exp"))

        if self.acsf and self.rank == 0:
            self.add_acsf_plots()        


        ########################################################################
        ### Everything Below is Standard
        ########################################################################
        if self.rank == 0:
            ## Add ibslib tag. User can easily turn this off if desired. 
            if timestamp == True:
                self.add_time()
            if tag == True:
                self.add_tag()
                        
            self._generate_report(figname=figname, savefig_kw=savefig_kw)
            
            if write_json:
                print("Writing Json")
                self.write_json()
            
            if write_remake: 
                self.write_remake()


    def add_acsf_plots(self):
        """
        Reads in RSF descriptor for IP and GA. Then plots the row of ACSF 
        projection plots. 

        """
        ## Read in ga and ip pools with RSF calculated
        self.ip_dict = read(self.ip_path+"_acsf")
        self.ga_dict = read(self.ga_path+"_acsf")

        ip_df = get(self.ip_dict, "prop", ["RSF", "energy", "Iteration"])
        ga_df = get(self.ga_dict, "prop", ["RSF", "energy", "Iteration"])

        ## Prepare descriptor matrix
        ip_matrix = np.vstack(ip_df["RSF"].values)
        ga_matrix = np.vstack(ga_df["RSF"].values)
        matrix = np.vstack([ip_matrix,ga_matrix])

        ## Prepare targets
        energy_targets = np.hstack([ip_df["energy"].values,
                                    ga_df["energy"].values])
        it_targets = np.hstack([ip_df["Iteration"].values,
                                ga_df["Iteration"].values])

        Z = self.conf_dict["run_settings"]["num_molecules"]
        energy_targets = correct_energy(energy_targets.tolist(),
                                    nmpc=Z)

        ## Prepare experimental information
        if len(self.exp_path) > 0:
            exp_acsf_path = os.path.join(self.report_struct_path,
                                         "exp_acsf")
            exp_dict = read(exp_acsf_path)
            exp_df = get(exp_dict, "prop", ["RSF", "energy", "Iteration"])
            exp_data = \
            {
                "features": exp_df["RSF"].values.tolist(),
                "energy": 0,
                "norm": True,
            }
        else:
            exp_data = \
            {
                "features": [],
                "energy": 0,
                "norm": True,
            }

        ## Setup colormaps
        energy_colormap_kw = \
        {
            "cmap": "hot",
            "truncate":
                {
                    "minval": 0.0,
                    "maxval": 1.0,
                    "n": 10000,
                },
            "ylabel": "Relative Energy, kJ$\cdot$mol$^{-1}$",
            "ylabel_kw":
                {
                    "rotation": 270,
                    "labelpad": 20,
                    "fontsize": 16
                },
            "ticks": [],
            "ticklabels": []
        }
        it_colormap_kw = \
        {
            "cmap": "cividis",
            "truncate":
                {
                    "minval": 0.0,
                    "maxval": 1.0,
                    "n": 10000,
                },
            "ylabel": "GA Iteration",
            "ylabel_kw":
                {
                    "rotation": 270,
                    "labelpad": 20,
                    "fontsize": 16
                },
            "ticks": [],
            "ticklabels": []
        }

        ## Add plots
        self.centered_plot(
            "pca_exp({}, targets={}, exp_data={}, colormap={}, ax=ax)"
                    .format(matrix.tolist(), energy_targets, exp_data,
                    energy_colormap_kw))
        self.centered_plot(
            "pca_exp({}, targets={}, exp_data={}, plot_IP={}, colormap={}, ax=ax)"
                    .format(matrix.tolist(), it_targets.tolist(), exp_data,
                    True, it_colormap_kw))


    def calc_acsf(self, struct_path):
        """
        Calculates the RSF descriptors for files in the struct_path

        """
        ## Create and manage folders for ACSF calculation
        output_dir = struct_path+"_acsf"
        calc_dir = struct_path + "_temp"
        if self.rank == 0:
            check_dir(output_dir)
            check_dir(calc_dir)
        self.comm.Barrier()

        s = read(struct_path)
        temp = BaseACSF(s, 0)
        unique_ele = list(temp.unique_ele)

        ## These are hard coded.
        ## I would find it unlikely anyone will really want to change these
        ## settings anytime in the near to distance future. It will only
        ## make it more complicated for the average user if I expose these
        ## settings to the API. 
        RSF_kw = \
            {
                "struct_dict": {},
                "cutoff": 12,
                "unique_ele": unique_ele, 
                "force": False,
                "n_D_inter": 12, 
                "init_scheme": "shifted",
                "eta_range": [0.05,0.5], 
                "Rs_range": [1,10],
                "del_neighbor": True
            }
        driver_kw = \
            {
                "file_format": "struct",
                "cutoff": 12,
                "prop_name": "",
            }

        rsf = RSF(**RSF_kw)
        driver = Driver(rsf, **driver_kw)

        check_kw = \
                {
                    "struct_dir": struct_path,
                    "output_dir": output_dir,
                    "calc_dir": calc_dir,
                    "comm": self.comm,
                    "calculator": driver, 
                }
        c = Check(**check_kw)
        c.calc()
        self.comm.Barrier()

        ## Cleanup
        if self.rank == 0:
            if os.path.exists(calc_dir):
                shutil.rmtree(calc_dir)

    def add_row_hist_plots(self):
        """
        Creates row of plots for volume histogram and space group hist. 

        """
        ## Make sure space group and volume are populated in properties
        for struct_id,struct in self.ip_dict.items():
            struct.get_space_group()
            struct.get_unit_cell_volume()
        for struct_id,struct in self.ga_dict.items():
            struct.get_space_group()
            struct.get_unit_cell_volume()

        ip_df = get(self.ip_dict, "prop", ["space_group", "unit_cell_volume"])
        ga_df = get(self.ga_dict, "prop", ["space_group", "unit_cell_volume"])
        
        ## Get number of bins for volume histogram
        volume_values = np.hstack([ga_df["unit_cell_volume"].values, 
                                    ip_df["unit_cell_volume"].values],
                                    ).astype(np.float)
        rounded_values = np.round(volume_values/5)*5
        unique = np.unique(rounded_values)
        volume_bins = len(unique)

        volume_hist_kw = \
            {
                "xlabel_kw":
                    {
                        "xlabel": "Unit Cell Volume, $\AA^3$",
                        "fontsize": 16,
                        "labelpad": 10,
                    },
                "ylabel_kw":
                    {
                        "ylabel": "Number of Structures",
                        "fontsize": 16,
                        "labelpad": 10, 
                    },
                "bins": volume_bins+20,
                "bar_kw":
                    {
                    "edgecolor": "k",
                    "color_list": ["tab:blue", "tab:red"],
                    "alpha_list": [],
                    },
                "legend_kw":  
                    {
                        "labels": ["Final GA Pool", "Initial Pool"],
                        "loc": [0,1.1],
                    },
                "xticks":  
                {
                    "xlim": [min(volume_values)-50, max(volume_values)+50],
                    "xticks_kw":
                        {
                            "ticks": [],
                        },
                    "xticklabels_kw": 
                        {
                            "labels": [],
                            "fontsize": 12,
                        },
                    "FormatStrFormatter": "%i"
                },
                "yticks":
                    {
                        "ylim": [],
                        "yticks_kw":
                            {
                                "ticks": [],
                            },
                        "yticklabels_kw": 
                            {
                                "labels": [],
                                "fontsize": 12,
                            },
                        "FormatStrFormatter": "%i"
                    }
            }

        ## Get number of unique space groups
        spg_values = np.hstack([ga_df["space_group"].values, 
                                    ip_df["space_group"].values],
                                    )

        unique_spg_values = np.unique(spg_values).tolist()
        ga_spg_kw = \
        {
        "spg_values": spg_values.tolist(),
        "general_spg_values": unique_spg_values,
        }
        ip_spg_kw = \
        {
        "spg_values": ip_df["space_group"].values.tolist(),
        "general_spg_values": unique_spg_values,
        "general_bar_kw":
            {
                "width": 0.8,
                "color": "tab:red",
                "edgecolor": "k"
            },
        }

        self.add_row_plots(
            ["hist({},ax=ax,**{})".format(
                [volume_values.tolist(),
                 ip_df["unit_cell_volume"].values.tolist()],
                volume_hist_kw),
            # "hist({},ax=ax,**{})".format([spg_values.tolist(),
            #                         ip_df["space_group"].values.tolist()],
            #                         spg_hist_kw)],
            "plot_spg_hist(**{}, ax=ax)".format(ga_spg_kw)+
            "\nplot_spg_hist(**{}, ax=ax)".format(ip_spg_kw)],
            height=5)


    def add_row_energy_plots(self):
        """
        Creates row of plots with average energy as a function of GA iteration
        on the left and minimum energy as a function of GA iteration on the 
        right. 

        """
        Z = self.conf_dict["run_settings"]["num_molecules"]

        ip_energy_df = get(self.ip_dict, "prop", ["energy"])
        ga_energy_df = get(self.ga_dict, "prop", ["energy", "Iteration"])
        ga_energy_df = ga_energy_df.sort_values("Iteration")

        ########################################################################
        ### Prepare the min iteration values
        ########################################################################
        min_values = []
        ip_min_value = min(ip_energy_df["energy"].values)
        min_values.append(ip_min_value)

        ## Append Running min
        ga_energy = ga_energy_df["energy"].values
        for it_idx in range(ga_energy.shape[0]):
            end_it_idx = it_idx + 1
            temp_min_value = min(ga_energy[:end_it_idx])
            temp_min_value = min(temp_min_value,ip_min_value)
            min_values.append(temp_min_value)

        min_corrected_values = correct_energy(min_values,
                                    nmpc=Z)

        ########################################################################
        ### Prepare the avg iteration values
        ########################################################################
        avg_values = []
        ip_energy = ip_energy_df["energy"].values
        ip_avg_value = np.mean(ip_energy)
        avg_values.append(ip_avg_value)

        ## Create list to use for average operation
        list_to_avg = ip_energy.tolist()
        ga_energy = ga_energy_df["energy"].values
        [list_to_avg.append(x) for x in ga_energy]
        list_to_avg = np.array(list_to_avg)

        ## Use ip offset so ip values are included in iteration average 
        ip_offset = ip_energy.shape[0]
        for it_idx in range(ga_energy.shape[0]):
            end_it_idx = it_idx + ip_offset
            temp_avg_value = np.mean(list_to_avg[:end_it_idx])
            avg_values.append(temp_avg_value)

        ## Use minimum from min_values as global min for avg plot
        avg_values = correct_energy(avg_values,
                                    nmpc=Z,
                                    global_min=min(min_values))

        ## Can include all values in avg_it plot however doesn't look
        ## good. For now, not using this. 
        all_values = [ip_avg_value]
        [all_values.append(x) for x in ga_energy]
        all_values = correct_energy(all_values,
                                    nmpc=Z,
                                    global_min=min(min_values))

        self.add_row_plots(
            ["avg_it({},ax=ax)".format(avg_values),
                "min_it({},ax=ax)".format(min_corrected_values)],
            height=5)

    
    def collect_structures(self):
        """
        Collects all structures from the GA. In addition, it will perform all
        processing of the structures. This includes removing the initial pool
        from the GA pool and adjusting the ID, which is the number the struct
        was added, such that it corresponds to the GA iteration. 

        """
        ip_path = os.path.join(self.report_struct_path,
                                "ip")
        ga_path = os.path.join(self.report_struct_path,
                                "ga")
        exp_path = os.path.join(self.report_struct_path,
                                "exp")
        
        ########################################################################
        ### This is where duplicate checking should be done, but it's not
        ### for now because I would like it to be parallelized.
        ### Let's assume for now that nothing is a duplicate. 
        ########################################################################

        ## Remove initial pool from ga_dict
        ga_id = [x for x in self.ga_dict.keys()]
        for struct_id in ga_id:
            if struct_id in self.ip_dict:
                del(self.ga_dict[struct_id])

        ## Reorder the ID of ga_dict to match true GA iteration
        id_df = get(self.ga_dict, "prop", ["ID"])
        id_df = id_df.sort_values("ID")

        ## Plus 1 because the iteration 0 is reserved for the IP
        for idx,struct_id in enumerate(id_df.index):
            self.ga_dict[struct_id].properties["Iteration"] = idx+1

        for struct_id,struct in self.ip_dict.items():
            struct.properties["Iteration"] = 0

        ## Can safely assume overwrite because ACSF is stored in another 
        ## folder. 
        write(ip_path, self.ip_dict, overwrite=True)
        write(ga_path, self.ga_dict, overwrite=True)

        ## Get experimental structure
        if len(self.exp_path) > 0:
            s = read(self.exp_path)
            temp_dict = {s.struct_id: s}
            write(exp_path, temp_dict, overwrite=True)


    def add_settings(self):

        ### Add Modules Section
        modules_str = "Modules\\n"
        height = 0
        for module_name,value in self.conf_dict["modules"].items():
            modules_str += "{}: {}\\n".format(module_name,value)
            height += 0.25

        if height < 0:
            heigh = 1

        self.add_textbox( 
                    modules_str, 
                    text_loc=[0.025,0.5],
                    height=3,
                    edgecolor="w",
                    text_kw =
                        {
                          "horizontalalignment": "left",
                          "verticalalignment": "center",
                          "fontsize": 14,
                          "wrap": True,
                        },
                    )
        
        ## Property section
        if self.conf_dict["modules"]["property_module"] !=  "none":
            self.add_textbox( 
                    "Property", 
                    text_loc=[0.025,0.5],
                    height=1,
                    edgecolor="w",
                    text_kw =
                        {
                          "horizontalalignment": "left",
                          "fontsize": 14,
                          "wrap": True,
                        },
                    )
            
            prop_str = ""
            height = 0
            for prop_name,value in self.conf_dict["property"].items():
                prop_str += "{}: {}\\n".format(prop_name,value)
                height += 0.25

            if height < 0:
                height = 1
            
            self.add_textbox( 
                    modules_str, 
                    text_loc=[0.1,0],
                    height=int(height),
                    edgecolor="w",
                    text_kw =
                        {
                          "horizontalalignment": "left",
                          "fontsize": 12,
                          "wrap": True,
                        },
                    )
        
        ## Initial Pool Information
        ip_str = "Initial Pool Folder: {}".format(
            self.conf_dict["initial_pool"]["user_structures_dir"])
        
        self.add_textbox( 
                    ip_str, 
                    text_loc=[0.025,0.5],
                    height=1,
                    edgecolor="w",
                    text_kw =
                        {
                          "horizontalalignment": "left",
                          "fontsize": 14,
                          "wrap": True,
                        },
                    )

        ## Most important GA settings that should be monitored by user
        GA_str = "GA Settings\\n"
        GA_str += "Z: {}\\n".format(
            self.conf_dict["run_settings"]["num_molecules"])
        GA_str += "Target Volume: {}\\n".format(
            self.conf_dict["cell_check_settings"]["target_volume"])
        GA_str += "Minimum SR: {}\\n".format(
            self.conf_dict["cell_check_settings"]["specific_radius_proportion"])
        GA_str += "Crossover Probability: {}\\n".format(
            self.conf_dict["crossover"]["crossover_probability"])
        
        self.add_textbox( 
                    GA_str, 
                    text_loc=[0.025,0.5],
                    height=2,
                    edgecolor="w",
                    text_kw =
                        {
                          "horizontalalignment": "left",
                          "verticalalignment": "center",
                          "fontsize": 14,
                          "wrap": True,
                        },
                    )

        struct_str = "Number of Structures\\n"
        struct_str += "    GA Pool: {}\\n".format(len(self.ga_dict))
        struct_str += "    Initial Pool: {}\\n".format(len(self.ip_dict))
        struct_str +="Generated by GA: {}".format(len(self.ga_dict) - 
                                                  len(self.ip_dict))

        self.add_textbox(
            struct_str, 
            text_loc=[0.025,0.50],
            height=2,
            edgecolor="w",
            text_kw =
                {
                    "horizontalalignment": "left",
                    "verticalalignment": "center",
                    "fontsize": 14,
                    "wrap": True,
                },)
        
            

    def get_struct_dir(self):
        """
        Using the current working directory, finds the correct structure
        directory that contains all the structures in the GA pool.

        """
        if not os.path.exists("structures"):
            return ""
        
        stoic_folder_list = os.listdir("structures")
        stoic_folder = []
        for folder_name in stoic_folder_list: 
            if ":" in folder_name:
                stoic_folder.append(folder_name)
        
        if len(stoic_folder) != 1:
            raise Exception("Stoichiometry folder for GA structures "+
            "was not properly identified. Check that there is a "+
            "folder name of the correct stoiciometry in the direcotry "+
            "{}".format(os.path.abspath("structures")))
        
        stoic_folder_path = os.path.join("structures/{}".format(
            stoic_folder[0]))

        GA_pool_path = os.path.join(stoic_folder_path, "0")
        ## Now check that there is the 0/ folder
        if not os.path.exists(GA_pool_path):
            raise Exception("GA pool path does not exist. "+
                "Please try again after GAtor creates the folder: {}"
                .format(GA_pool_path))

        return GA_pool_path

    
    def get_ip_structs(self):
        """
        Check IP path in conf file and read in structures.

        """
        path_from_conf = self.conf_dict["initial_pool"]["user_structures_dir"]

        if not os.path.isdir(path_from_conf):
            raise Exception("Initial pool folder from conf file was not "+
                "found: {}".format(path_from_conf))
        
        if not check_struct_dir(path_from_conf):
            raise Exception("Initial pool folder was not identified "+
                "as a folder containing Structure files: {}"
                .format(path_from_conf))
        
        s = read(path_from_conf)

        return s

    def get_ga_structs(self):
        """
        Read in structures from the GA pool. 

        """
        struct_dict = {}

        desired_ext = "json"
        file_format = "json"

        ## Trying to protect against any errors that GAtor may make
        for temp_struct_dir in os.listdir(self.struct_dir):
            temp_struct_path = os.path.join(self.struct_dir, temp_struct_dir)
            json_path = os.path.join(temp_struct_path, 
                                     "{}.json".format(temp_struct_dir))
            s = read(json_path)
            s.struct_id = temp_struct_dir
            struct_dict[s.struct_id] = s

        return struct_dict



    def from_dict(self, ref_dict):
        """
        Load in the state of the entire class from a reference dictionary. 
        
        """
        pass
    
    
    def as_dict(self):
        """
        Return the state of the entire class as a dictionary. 
        
        """
        pass
